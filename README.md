# Реализация ReID модели с помощью CLIP-подобных моделей

## Постановка задачи

В данной работе предлагается улучшить модели задачи реидентификации людей -
распознавание людей с многих камер, то есть нахождение одного и того же человека
на разных камерах (картинках). Улучшать модели можно с помощью использования
текстового описания, который подается на вход вместе с изображением. Именно про
это CLIP-ReID модели. В рамках данной работы будет представлена модель,
распознающая людей, на основе CLIP-ReID. Основная статья -
https://arxiv.org/pdf/2211.13977

## Формат входных и выходных данных

На вход подается батч изображений размера B = P×K (query), где P количество
различных классов людей в батче, и K количество изображений каждого класса.
Также необходимо, чтобы была некоторая галерея изображений среди которых искать
совпадение (galery) формата картинка-лейбл. На выходе для каждого изображения из
query получаем наиболее подходящий label из galery.

## Метрики

- Сumulative matching characteristics (CMC) at Rank-1 (R1)
- Mean average precision (mAP)

Данные метрики выбраны, потому что являются основными в статьях при сравнении с
sota моделями.

На выходе получаем по тестовому датасету следующие метрики:

```
Test Results - Rank-1: 95.19%
Test Results - Rank-5: 98.57%
Test Results - mAP: 88.33%
```

## Валидация

Датасет рандомно разделяется на тренировочный и тестовый в соотношение 1:3 (это
уже проделано в предоставленных датасетах).

## Данные

https://paperswithcode.com/dataset/market-1501 - Market-1501 Статистика:

```
----------------------------------------
subset   | # ids | # images | # cameras
----------------------------------------
train    |   751 |    12936 |         6
query    |   750 |     3368 |         6
gallery  |   751 |    15913 |         6
----------------------------------------
```

## Baseline

Используются полученные метрики в статье

## Основная модель

Модель состоит из двух энкодеров (текстового и для изображений), в основном за
текстовый берут трансформер по типу ViT-B/16, а для изображения ResNet-50. За
основу архитектуры берется CLIP модель. Обучение состоит из двух стадий:

1. Обучаются только текстовые промты
2. Обучается только image encoder На выходе получаем обученный image encoder под
   подставленную задачу, который дальше используется для получения фича вектора
   по изображению ![Итоговая модель](readme_images/model.png)

# Запуск модели

## Характеристики железа

- одна карточка GPU Nvidia GeForce RTX 2080, память 11 Gb
- RAM: 256 Gb
- CPU: Intel Xeon Gold 6136 v4, 24 ядра

## Setup

Скачать репозиторий:

```
git clone https://github.com/anyatamax/reid-task.git
cd reid-task
```

Установить poetry и настроить его конфигурацию, чтобы использовать совместно с
conda:

```
pip install pipx
pipx install poetry
pipx ensurepath

poetry config virtualenvs.path "path_to_your_conda_envs"
poetry config virtualenvs.create false
```

Активировать conda окружение:

```
conda activate <your virtual env name>
```

Установить все зависимости:

```
poetry install
```
